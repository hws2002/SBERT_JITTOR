{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "663b93c0",
      "metadata": {},
      "source": [
        "# Downstream Demo (MR)\n",
        "\n",
        "Step-by-step MR training + evaluation without helper functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874c3654",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Repository path setup (run this only if you get import errors)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def _find_repo_root(start: Path):\n",
        "    for p in [start] + list(start.parents):\n",
        "        if (p / 'model' / 'sbert_model.py').is_file():\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "repo_root = _find_repo_root(Path.cwd())\n",
        "if repo_root is None:\n",
        "    print('SBERT_JITTOR root not found. Set sys.path manually.')\n",
        "else:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "    os.chdir(repo_root)\n",
        "    print(f'Using repo root: {repo_root}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69483060",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) HF cache + warning control\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "os.environ.setdefault('HF_HOME', './.hf_cache')\n",
        "os.environ.pop('TRANSFORMERS_CACHE', None)\n",
        "warnings.filterwarnings(\n",
        "    'ignore',\n",
        "    message='Using `TRANSFORMERS_CACHE` is deprecated',\n",
        "    category=FutureWarning,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a77c634d",
      "metadata": {},
      "source": [
        "## 3) Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f25aa5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import jittor as jt\n",
        "from jittor import nn\n",
        "from jittor.dataset import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model.sbert_model import SBERTJittor\n",
        "from utils.data_loader import prepare_text_classification_dataset\n",
        "from utils.jt_utils import _to_jittor_batch_single, setup_device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80777ca1",
      "metadata": {},
      "source": [
        "## 4) Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67c2e6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = './data'\n",
        "batch_size = 32\n",
        "max_length = 128\n",
        "repo_id = 'Kyle-han/roberta-base-nli-mean-tokens'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cba14b5",
      "metadata": {},
      "source": [
        "## 5) Device setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66cedd4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "setup_device(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "406f9d5e",
      "metadata": {},
      "source": [
        "## 6) Load model + tokenizer from HF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10386b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "model, tokenizer, _ = SBERTJittor.from_pretrained(\n",
        "    repo_id,\n",
        "    return_tokenizer=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6091564",
      "metadata": {},
      "source": [
        "## 7) Load MR datasets + DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80db2258",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = prepare_text_classification_dataset(\n",
        "    data_dir=data_dir,\n",
        "    dataset_name='MR',\n",
        "    split='train',\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=max_length,\n",
        "    cache_dir=None,\n",
        "    overwrite_cache=False,\n",
        "    tokenize_batch_size=1024,\n",
        ")\n",
        "val_ds = prepare_text_classification_dataset(\n",
        "    data_dir=data_dir,\n",
        "    dataset_name='MR',\n",
        "    split='validation',\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=max_length,\n",
        "    cache_dir=None,\n",
        "    overwrite_cache=False,\n",
        "    tokenize_batch_size=1024,\n",
        ")\n",
        "test_ds = prepare_text_classification_dataset(\n",
        "    data_dir=data_dir,\n",
        "    dataset_name='MR',\n",
        "    split='test',\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=max_length,\n",
        "    cache_dir=None,\n",
        "    overwrite_cache=False,\n",
        "    tokenize_batch_size=1024,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "363059c7",
      "metadata": {},
      "source": [
        "## 8) Train (one epoch demo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acdfa9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = nn.Linear(model.output_dim, 2)\n",
        "optimizer = nn.Adam(list(model.parameters()) + list(clf.parameters()), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_ds) / batch_size)\n",
        "model.train()\n",
        "clf.train()\n",
        "for step, batch in enumerate(tqdm(train_loader, total=steps_per_epoch, desc='MR train'), 1):\n",
        "    jt_batch = _to_jittor_batch_single(batch)\n",
        "    reps = model.encode(jt_batch['input_ids'], jt_batch['attention_mask'], jt_batch.get('token_type_ids'))\n",
        "    logits = clf(reps)\n",
        "    loss = loss_fn(logits, jt_batch['labels'])\n",
        "    optimizer.step(loss)\n",
        "    if step >= steps_per_epoch:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eab2087",
      "metadata": {},
      "source": [
        "## 9) Evaluation (validation + test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb523c77",
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_loop(loader, name):\n",
        "    model.eval()\n",
        "    clf.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    total_loss = 0.0\n",
        "    with jt.no_grad():\n",
        "        for batch in tqdm(loader, total=math.ceil(len(loader.dataset) / batch_size), desc=f'{name} eval'):\n",
        "            jt_batch = _to_jittor_batch_single(batch)\n",
        "            reps = model.encode(jt_batch['input_ids'], jt_batch['attention_mask'], jt_batch.get('token_type_ids'))\n",
        "            logits = clf(reps)\n",
        "            loss = loss_fn(logits, jt_batch['labels'])\n",
        "            preds = jt.argmax(logits, dim=1)[0]\n",
        "            total_correct += jt.sum(preds == jt_batch['labels']).item()\n",
        "            total_samples += jt_batch['labels'].shape[0]\n",
        "            total_loss += loss.item() * jt_batch['labels'].shape[0]\n",
        "    avg_loss = total_loss / max(total_samples, 1)\n",
        "    acc = total_correct / max(total_samples, 1) * 100\n",
        "    print({name: {'loss': avg_loss, 'accuracy': acc}})\n",
        "\n",
        "eval_loop(val_loader, 'MR validation')\n",
        "eval_loop(test_loader, 'MR test')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}