{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab84f2e5",
   "metadata": {},
   "source": [
    "# Downstream Demo (MR)\n",
    "\n",
    "This demo tests transfer ability by attaching a classification head to a pretrained SBERT encoder,\n",
    "then training on the MR sentiment dataset and evaluating performance.\n",
    "\n",
    "Flow:\n",
    "0) (Optional) Path setup + warning control (only if you hit import warnings/errors)\n",
    "1) Load config and device\n",
    "2) Load pretrained SBERT + tokenizer from HF\n",
    "3) Load datasets\n",
    "4) Train classifier head (SBERT frozen in this demo)\n",
    "5) Evaluate on validation + test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275a069",
   "metadata": {},
   "source": [
    "## 0) (Optional) Path setup and warning control\n",
    "\n",
    "- Use this only if you hit import errors in this notebook.\n",
    "- This step also silences noisy HF cache deprecation warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you get import errors\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the repo root and add it to sys.path\n",
    "# so `model/` and `utils/` can be imported in notebooks.\n",
    "def _find_repo_root(start: Path):\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'model' / 'sbert_model.py').is_file():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "if repo_root and str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "    print('Added repo root to sys.path:', repo_root)\n",
    "else:\n",
    "    print('Repo root not found or already on sys.path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional HF cache + warning control\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Put HF cache in a local folder for this notebook\n",
    "os.environ.setdefault('HF_HOME', './.hf_cache')\n",
    "# Avoid deprecated TRANSFORMERS_CACHE warning\n",
    "os.environ.pop('TRANSFORMERS_CACHE', None)\n",
    "# Silence the deprecation warning in output\n",
    "warnings.filterwarnings(\n",
    "    'ignore',\n",
    "    message='Using `TRANSFORMERS_CACHE` is deprecated',\n",
    "    category=FutureWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae724bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import jittor as jt\n",
    "from jittor import nn\n",
    "from jittor.dataset import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.sbert_model import SBERTJittor\n",
    "from utils.data_loader import prepare_text_classification_dataset, collate_text_classification\n",
    "from utils.jt_utils import _to_jittor_batch_single\n",
    "from utils.training_utils import setup_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf64e24",
   "metadata": {},
   "source": [
    "## 1) Load config and device\n",
    "\n",
    "Set basic runtime configuration and select CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff437e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic config\n",
    "# - data_dir: local dataset root\n",
    "# - repo_id: HF model id to load\n",
    "\n",
    "data_dir = './data'\n",
    "batch_size = 32\n",
    "max_length = 128\n",
    "repo_id = 'Kyle-han/roberta-base-nli-mean-tokens'\n",
    "\n",
    "setup_device(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc23c1",
   "metadata": {},
   "source": [
    "## 2) Load pretrained SBERT + tokenizer from HF\n",
    "\n",
    "Fetch the model and tokenizer from the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained SBERT + tokenizer\n",
    "model, tokenizer, _ = SBERTJittor.from_pretrained(\n",
    "    repo_id,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2c77a",
   "metadata": {},
   "source": [
    "## 3) Load datasets\n",
    "\n",
    "Load MR train/validation/test splits and build Jittor DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MR datasets and build dataloaders\n",
    "train_ds = prepare_text_classification_dataset(\n",
    "    data_dir=data_dir,\n",
    "    dataset_name='MR',\n",
    "    split='train',\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    cache_dir=None,\n",
    "    overwrite_cache=False,\n",
    "    tokenize_batch_size=1024,\n",
    ")\n",
    "val_ds = prepare_text_classification_dataset(\n",
    "    data_dir=data_dir,\n",
    "    dataset_name='MR',\n",
    "    split='validation',\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    cache_dir=None,\n",
    "    overwrite_cache=False,\n",
    "    tokenize_batch_size=1024,\n",
    ")\n",
    "test_ds = prepare_text_classification_dataset(\n",
    "    data_dir=data_dir,\n",
    "    dataset_name='MR',\n",
    "    split='test',\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    cache_dir=None,\n",
    "    overwrite_cache=False,\n",
    "    tokenize_batch_size=1024,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_batch=collate_text_classification,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_batch=collate_text_classification,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_batch=collate_text_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45227529",
   "metadata": {},
   "source": [
    "## 4) Train classifier head\n",
    "\n",
    "Freeze the SBERT encoder and train a lightweight classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a small classifier head on top of frozen SBERT\n",
    "for param in model.parameters():\n",
    "    param.stop_grad()\n",
    "\n",
    "clf = nn.Linear(model.output_dim, 2)\n",
    "optimizer = nn.Adam(clf.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "steps_per_epoch = math.ceil(len(train_ds) / batch_size)\n",
    "model.train()\n",
    "clf.train()\n",
    "for step, batch in enumerate(tqdm(train_loader, total=steps_per_epoch, desc='MR train'), 1):\n",
    "    jt_batch = _to_jittor_batch_single(batch)\n",
    "    reps = model.encode(jt_batch['input_ids'], jt_batch['attention_mask'], jt_batch.get('token_type_ids'))\n",
    "    logits = clf(reps)\n",
    "    loss = loss_fn(logits, jt_batch['labels'])\n",
    "    optimizer.step(loss)\n",
    "    if step >= steps_per_epoch:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58df611",
   "metadata": {},
   "source": [
    "## 5) Evaluate on validation + test set\n",
    "\n",
    "Measure accuracy and loss on held-out splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop for validation/test\n",
    "\n",
    "def eval_loop(loader, name, dataset_len):\n",
    "    model.eval()\n",
    "    clf.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "    total_batches = math.ceil(dataset_len / batch_size)\n",
    "    with jt.no_grad():\n",
    "        for batch in tqdm(loader, total=total_batches, desc=f'{name} eval'):\n",
    "            jt_batch = _to_jittor_batch_single(batch)\n",
    "            reps = model.encode(jt_batch['input_ids'], jt_batch['attention_mask'], jt_batch.get('token_type_ids'))\n",
    "            logits = clf(reps)\n",
    "            loss = loss_fn(logits, jt_batch['labels'])\n",
    "            preds = jt.argmax(logits, dim=1)[0]\n",
    "            total_correct += jt.sum(preds == jt_batch['labels']).item()\n",
    "            total_samples += jt_batch['labels'].shape[0]\n",
    "            total_loss += loss.item() * jt_batch['labels'].shape[0]\n",
    "    avg_loss = total_loss / max(total_samples, 1)\n",
    "    acc = total_correct / max(total_samples, 1) * 100\n",
    "    print({name: {'loss': avg_loss, 'accuracy': acc}})\n",
    "\n",
    "# Validate and test\n",
    "\n",
    "eval_loop(val_loader, 'MR validation', len(val_ds))\n",
    "eval_loop(test_loader, 'MR test', len(test_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}