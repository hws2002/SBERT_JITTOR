{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation (STS)\n",
        "\n",
        "Evaluate a STS datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjust paths before running\n",
        "BASE_MODEL = \"bert-base-uncased\"\n",
        "DATA_DIR = \"./data\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer                                                                                                        \n",
        "import jittor as jt                                                                                                                           \n",
        "                                                                                                                                            \n",
        "from model.sbert_model import SBERTJittor                                                                                                     \n",
        "                                                                                                                                            \n",
        "model = SBERTJittor(                                                                                                                          \n",
        "    pretrained=True,                                                                                                                          \n",
        "    model_id=\"Kyle-han/roberta-base-nli-mean-tokens\",                                                                                         \n",
        "    pooling=\"mean\",                                                                                                                           \n",
        ")                                                                                                                                             \n",
        "                                                                                                                                            \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Kyle-han/roberta-base-nli-mean-tokens\", use_fast=True)                                             \n",
        "                                                                                                                                            \n",
        "batch = tokenizer(\"hello world\", return_tensors=\"np\")                                                                                         \n",
        "input_ids = jt.array(batch[\"input_ids\"])                                                                                                      \n",
        "attention_mask = jt.array(batch[\"attention_mask\"])                                                                                            \n",
        "token_type_ids = jt.array(batch[\"token_type_ids\"]) if \"token_type_ids\" in batch else None                                                     \n",
        "                                                                                                                                            \n",
        "emb = model.encode(input_ids, attention_mask, token_type_ids)                                                                                 \n",
        "print(emb.shape)                                                                                                                              \n",
        "                "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
